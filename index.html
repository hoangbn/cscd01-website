<!DOCTYPE html>
<html>

<head>
    <meta name="google-site-verification" content="elVfiCtvNaXIwl3srSvoA_Ay3mf5q6cG_ZVhQaOJMsI" />
    <title>The Lobbyists</title>
    <!-- Font -->
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">

    <!-- Latest compiled and minified CSS -->
    <!--<link rel="stylesheet" href="./bootstrap/css/bootstrap.min.css">-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

    <!-- jQuery library -->
    <!--<script src="./bootstrap/js/jquery.min.js"></script>-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

    <!-- Latest compiled JavaScript -->
    <!--<script src="./bootstrap/js/bootstrap.min.js"></script>-->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    <!-- Custom stylesheet -->
    <link rel="stylesheet" type="text/css" href="./css/stylesheetnew.css">

    <!-- Icon to page -->
    <link rel="icon" href="./images/icon.png" type="img/gif">
    <script src="/js/modernizr.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>


<body id="myPage" data-spy="scroll" data-target=".navbar">
    <nav class="navbar navbar-fixed-top navbar-default">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar" aria-expanded="false">
	        <span class="sr-only">Toggle navigation</span>
	        <span class="icon-bar"></span>
	        <span class="icon-bar"></span>
	        <span class="icon-bar"></span>
	      </button>
                <a class="navbar-brand" href="#home">LOBBYISTS</a>
            </div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="#about">about</a></li>
                    <li><a href="#skills">team</a></li>
                    <li><a href="#agreement">agreement</a></li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Deliverables <span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="#deliverable4">deliverable 4</a></li>
                            <li><a href="#deliverable3">deliverable 3</a></li>
                            <li><a href="#deliverable2">deliverable 2</a></li>
                            <li><a href="#deliverable1">deliverable 1</a></li>
                        </ul>
                    </li>

                </ul>
            </div>
        </div>
        <!-- /.container-fluid -->
    </nav>


    <div id="home" class="jumbotron page-header">
        <div class="container text-center">
            <img src="images/team.jpg" width="75%"><br>
            <p>In Order Left to Right: Dax Patel, Salim Mansour, Julia Yan, Hoang Nguyen, William Song</p>
        </div>
    </div>

    <div class="container-fluid wide" id="about" style="height: auto; margin-bottom: 30px">
        <h1 class="text-center">The Lobbyists</h1>
        <div class="about-item text-center" style="font-size: 20px;width: 75%; margin:auto">
            <h2>Goals</h2>
            <p>To contribute to the greater scientific community by adding to open-source tools that help researchers process their data in more efficient ways. To primarily focus on helping researchers with little coding experience to be able to use the
                pandas' tools and libraries in a user-friendly way.</p>

            <h2>Strengths</h2>
            <ul>
                <li>Design and animation</li>
                <li>Web design and development</li>
                <li>Database management</li>
                <li>Testing</li>
            </ul>
        </div>
    </div>

    <div class="container-fluid wide" id="skills" style="background-color: #CCDDCE; height: auto;">
        <h1 class="text-center">Who are we?</h1>

        <div class="row">
            <div class="col-xs-6 col-md-3">
                <img src="images/salim.png" alt="">
            </div>
            <div class="col-xs-12 col-md-9">
                <h2><a href="https://slimnsour.me/" target="_blank">Salim Mansour</a></h2>
                <p>
                    I'm currently completing my Specialist in Software Engineering at the University of Toronto. I love problem-solving and learning new technologies, and I am fortunate to have been given the opportunity to demonstrate this at Geosoft Inc. and the Centre
                    for Addiction and Mental Health. At Geosoft I worked as an Automated Test Engineer, testing their main product Oasis montaj, decreasing the average failure rate by 30% and presenting results at weekly meetings. At the Centre for Addiction
                    and Mental Health, I was a Neuroimaging Research Analyst, in which I designed and implemented my own preprocessing pipelines for diffusion imaging, and created a new pipeline tractify for tractography generation. I also have a deep
                    passion for games. My experience with the medium has encouraged me to be an executive of the first ever Game Dev Club at the University of Toronto and develop a solo project Balloonatics. I aim to combine my programming skills, team
                    player mindset, and love for games to be an indispensable asset to the game industry.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12 col-md-9">
                <h2>Hoang Nguyen</h2>
                <p>
                    I am in my third year at the University of Toronto Scarborough specializing in Software Engineering and minoring in Economics. I love everything about Computer Science but am currently focusing on exploring different aspects of Web Development. As an
                    intern at FPT Corporation, I helped develop a new educational website that assists students with their studies by providing them lectures, practice exercises, exams, and analyses their weaknesses. I also devised a way to efficiently
                    track and update some of the data inside the website, so that admin users do not have to do it manually. At Klick, I developed marketing emails and static websites to help pharmaceutical products get FDA approval, and get pushed to
                    market. Some of the frameworks that I used on my internships and in my projects are React, Spring Boot, Express, Flask. Outside work and school, I like to do sports such as MMA, soccer, badminton. I also love playing video games and
                    am currently trying to pick up game development as a hobby.
                </p>
            </div>
            <div class="col-xs-6 col-md-3">
                <img src="images/hoang.jpg" alt="">
            </div>
        </div>

        <div class="row">
            <div class="col-xs-6 col-md-3">
                <img src="images/dax.jpg" alt="">
            </div>
            <div class="col-xs-12 col-md-9">
                <h2><a href="https://www.linkedin.com/in/patedax/" target="_blank">Dax Patel</a></h2>
                <p>
                    I engage in work that feeds my curiosity. I often find myself busy with things, for which, I believe to have a big picture view. This is closest to the answer to why I chose to study Computer Science. At UofT, Faculty of Arts and Science, I got an opportunity
                    to remediate a Major Incident affecting the CHASS Data Centre involving a large PostgreSQL database (1.6 billion rows) and its data definition. Working alongside another coop student, I was able to bring back the CANSIM Data Set at
                    CHASS back live in under two months. I've learned and worked with a few web technologies such as Laravel, VueJS, Django, Spring Boot to use them during my work term and in my side projects. This helps me learn new technologies and
                    frameworks much faster as I need them. I am open to ideas and collaboration, that will help me gain practical experience and utilize my skill set. I am developing a deeper interest in Machine Learning by working on some interesting
                    assignments at UofT.
                    <br><br> Additionally, I have worked at UofT Scarborough as Peer Study Skills Coach and Teaching Assistant for Introductory Programming course. I enjoy teaching things I have known to understand really well, this made me more efficient
                    in the above positions and help me understand how a singular teaching style does not work well with students because of diverse learning styles.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-xs-12 col-md-9">
                <h2>William Song</h2>
                <p>
                    My passion lies in projects where I can make the world a better place. I have done this through work with organizations such as TEDx where I hosted an educational conference for my university. Another team I work with on one of my biggest projects is
                    aUToronto, where along with a team of over 80 student engineers, I have been developing a fully autonomous self-driving car from the ground up under General Motors. While I am a generalist and a quick learner first and foremost, my
                    primary expertise lies in systems engineering, software development, and online marketing. I am comfortable with most popular development languages (C, C++, Python, and Java) and a few less common languages and tools (ROS, Shell, and
                    Verilog). My primary duty is as a third-year undergraduate student at the University of Toronto Scarborough where I also work as a teaching assistant for a few undergraduate computer science courses.
                </p>
            </div>
            <div class="col-xs-6 col-md-3">
                <img src="images/william.jpg" alt="">
            </div>
        </div>

        <div class="row">
            <div class="col-xs-6 col-md-3">
                <img src="images/julia.png" alt="">
            </div>
            <div class="col-xs-12 col-md-9">
                <h2><a href="julesyan.com" target="_blank">Julia Yan</a></h2>
                <p>
                    I am a 5th-year co-op student studying Computer Science where I am specializing in Software Engineering. I have been coding since the tenth grade and hope to merge my love for visual arts and computers through web development. I am currently working as
                    a freelance web developer, a Full Stack Developer at the University of Toronto Faculty of Medicine Post Graduate Medical Education, a Designer and Web Developer at The Soap Box Press and as a Peer Coach at the University of Toronto
                    Scarborough Arts & Science Co-op.
                    <br><br> I have previously worked at TD Bank doing web development work in Wealth, and at Verto Inc, where I worked as a Full Stack Developer. These two opportunities have allowed me to explore development in a professional setting,
                    one with a focus on finance and the other developing healthcare software for many hospitals across Ontario.
                    <br><br> I am proud to say I am a recipient of Apple's 2017 WWDC Scholarship, where I was 1 out of 350 people worldwide and only female Canadian that year awarded a scholarship to attend Apple's annual developer's conference (WWDC)
                    in San Jose, California.
                </p>
            </div>
        </div>
    </div>

    <div class="container-fluid wide" id="agreement" style="height: auto;">
        <h1 class="text-center">Team Agreement</h1>
        <div class="about-item text-center" style="font-size: 20px;width: 75%; margin:auto">
            <h2>Methods of Communication</h2>
            <p>Discord channel: acts identically to Slack but has free voice calls and screen sharing.</p>

            <h2>Communication Response Times</h2>
            <ul>
                <li>A response to a directed message is expected within 1 business day of the original message being sent. The sender should tag the recipients (@name) for visibility.</li>
                <li>All team members should review daily messages in the discord to keep up to date on the project.</li>
                <li>For the 4 days leading up to a deliverable deadline, the response time is expected to be within 4 hours of the working hours.</li>
            </ul>

            <h2>Meeting Attendance</h2>
            <ul>
                <li>Face-to-face: Weekly Mondays at 5:00 pm-5:30 pm only if necessary. It must be planned ahead of time. Attendance for face-to-face meetings is expected.</li>
                <li>Online: daily online standups in a channel where you note what you have worked on for that day (do not need to update if no work was done that day).</li>
                <li>Will will take notes.</li>
            </ul>

            <h2>Meeting Preparation</h2>
            <p>Face-to-face meetings will have a certain goal. You only need to prepare materials relevant to achieving that goal.</p>

            <h2>Version Control</h2>
            <p>Github will be used. Commit anything to non-main branches. The main branch should always be a publishable project. The code must be reviewed before merging into the main branch by at least one other team member.</p>

            <h2>Division of Work</h2>
            <ul>
                <li>Upon analyzing and discussing each team member's strengths and weaknesses, they will choose the work that aligns the most with their skill set.</li>
                <li>For a situation where a team member is facing a significant learning curve for a task, they must reach out to a member who is most familiar with the task and get help. This must be identified by evaluating individual progress during daily
                    online standups.</li>
                <li>Work will be self-assigned at the beginning of every sprint and adjusted mid-sprint if necessary.</li>
            </ul>

            <h2>Submitting Deliverables</h2>
            <p>Everyone will contribute to writing deliverables. Julia will submit.</p>

            <h2>Contingency Planning</h2>
            <ul>
                <li>Team Member drops: Notify everyone else ASAP and we will redistribute work accordingly.</li>
                <li>If a team member acts against the interests of the team (misses meetings, doesn't do their assigned work, is academically dishonest) with no reasonable excuse: notify a TA or professor immediately for help from an instructor.</li>
            </ul>

            <div class="signatures">
                <img src="images/image1.png" alt="">
                <img src="images/image10.png" alt="">
                <img src="images/image2.png" alt="">
                <img src="images/image5.png" alt="">
                <img src="images/image8.png" alt="">
            </div>
        </div>
    </div>

    <div class="container-fluid wide deliverable" id="deliverable1" style="background-color: #CCDDCE; height: auto;">
        <h1 class="text-center">Deliverable 1</h1>

        <h2>Architecture of Pandas</h2>

        <h3>Introduction</h3>
        <p>First, we have a UML Package Diagram to show the overall structure of pandas:</p>
        <img src="images/deliverable1/overall.png" alt="">

        <h4>Pandas Object</h4>
        <p>
            In this structure, you can see that the majority of pandas is object-based. Pandas is focused around creating complex objects used for advanced data analysis, so a lot of its functionality is just creating those objects, and adding operations and extensions
            to supplement the objects.
        </p>
        <p>
            Some example PandasObjects that can be seen in this diagram are FrozenLists, NDFrames, and Blocks. These all inherit from the main PandasObject class, which we will get into more detail in the next section.
        </p>

        <h4>Operation</h4>
        <p>
            The Operations section has a main operation class, and is split into Unary and Binary Operation children. There is also a special MathCall operation child used for special math operations, but we did not include it in the diagram for simplicity. These
            operation classes allow pandas to extend the class of operations for scalability and use with other objects. We will also go into more detail on this in the following sections.
        </p>

        <h4>Extension</h4>
        <p>
            The Extension section is similar to the Operations section in that it allows pandas to define their own types for scalability. Some example types shown here are IntegerDType, BooleanDType, and StringDType. There are more ExtensionDType children that we
            are not showing here for simplicity, but the main point here is that pandas uses these types when constructing their objects for added functionality and efficiency.
        </p>


        <h3>Pandas Object and its extensibility</h3>
        <p>Next we have a more in depth look at the Objects section:</p>
        <img src="images/deliverable1/single1.png" alt="">
        <p style="margin-top: 10px;">
            This deeper look into the Objects section shows the types of functions and children PandasObjects can have.
        </p>
        <p>
            The children of PandasObjects each have functions that can be overridden by their children, and define what the object is used for. For example, FrozenList has a union and difference operation, defined exactly as a list union or difference operation in
            mathematics. These functions make it easy to see what an object is capable of and what each of its children will have/override.
        </p>
        <p>
            Furthermore, there exists subchildren for some of the PandasObjects. Some examples shown here are that NDFrame has DataFrame and Series subchildren, and Index has ExtensionIndex, MultiIndex, and NumericIndex subchildren. This shows that pandas uses inheritance
            to define more specific types of data structures and tools needed for their functionalities.
        </p>
        <p>
            *Note: There is an asterisk around Block because it is a more complex object we will go into more detail next.
        </p>

        <h3>Block Class</h3>
        <p>Now for a more in-depth look on what the Block class is about:</p>
        <img src="images/deliverable1/single2.png" alt="">
        <p style="margin-top: 10px;">
            In pandas, a block is an n-dimensional unit of a homogeneous type. It is used internally for holding values of a certain type, which is useful for managing analysis of several types in a programming language like Python.
        </p>
        <p>
            The main Block class has several functions that each of its children will inherit, like is_datelike(), internal_values(), and get_values(). These are all about getting information about the values that the Block is holding in some fashion, as that is
            its main role.
        </p>
        <p>
            There are several Block subchildren, such as DatetimeBlock, NumericBlock, and ObjectBlock. These can go even deeper as shown, branching off to BoolBlock, FloatBlock, etc. As you can see, pandas makes the effort to support different typing for clarity,
            which is useful for the wide array of data analysis that it is used for.
        </p>

        <h3>Implementation of Operations</h3>
        <img src="images/deliverable1/single3.png" alt="">
        <p style="margin-top: 10px;">
            Similarly to the Block section, the Operations section is split into different types for scalability purposes. It is also important to note that each operation is held as a string, as shown in the op string in attributes of Op.
        </p>
        <p>
            Like we mentioned before, there are Unary and Binary Operations that are the main children of Op. The Binary class has subchildren as well, splitting off into BinOp, and then into FilterBinOp and ConditionBinOp.
        </p>

        <h3>Detailed look</h3>
        <p>Putting it all together, we have a more detailed look between the classes in pandas:</p>
        <img src="images/deliverable1/detailed.png" alt="">


        <h2>Software Development Process: Kanban</h2>

        <h3>Description of the Process</h3>
        <p>We aim to make small, incremental changes to the Pandas project, for this reason, we choose Kanban as our Agile Methodology.</p>

        <h4>Why Agile</h4>
        <ul>
            <li>
                The issues that we will be working on may not have everything laid out for us to complete, so we want to be able to adapt to change and new plans we make to complete any given tasks.
            </li>
            <li>
                We also want to embrace change pretty easily as it is good for identifying new tasks to complete in a large codebase.

            </li>
            <li>
                We want to recognize the fact that we have a small team of experienced programmers, and spending too much planning would be wasted and restrictive as we can figure our way around tasks easily.
            </li>
            <li>
                Finally, we want simplicity in our development as it would be easier for us to understand the scope of our contribution, and it would be more likely to be integrated into the main codebase.
            </li>
        </ul>

        <h4>Why Kanban</h4>
        <ul>
            <li>
                The nature of issues we will be focusing on, align well with core principles of Kanban:
            </li>
            <li>
                Having a set of tasks visually represented makes it easier for us to take initiative and plan it out with other assignments.
                <ul>
                    <li>
                        <strong>Start with what you do know:<br/></strong>
                        <div class="tabbed">Considering Pandas is significantly large Software being improved and modified by many developers, Kanban’s versatility and flexibility will make it easy to implement the workflow and follow contributing guidelines set by panda’s
                            community.
                        </div>
                    </li>
                    <li>
                        <strong>Agree to Pursue Incremental, Evolutionary changes<br/></strong>
                        <div class="tabbed">Small changes to pandas due in next deliverable are the perfect candidate that will demonstrate minimum resistance to the ongoing development.</div>
                    </li>
                    <li>
                        <strong>Respect the current Process, Roles and Responsibilities<br/></strong>
                        <div class="tabbed">Rather than developing a groundbreaking library from scratch ourselves, our aim is to preserve current processes in place for pandas. As contributors, we aim to set reasonable expectations while maintaining respect for the current
                            process.
                        </div>
                    </li>
                    <li>
                        <strong>Encourage acts of leadership at all Levels<br/></strong>
                        <div class="tabbed">This principle especially aligns with the core principle of our team. We strive to achieve optimal performance in our tasks by leveraging each team member’s Strengths.</div>
                    </li>
                </ul>
            </li>
            <li>
                To fully follow the Kanban workflow we are using Github Project Boards set up Cards and necessary columns. This enables us to keep track of progress and contributions from each team member.
            </li>
            <li>
                Using Github Project Boards is the best choice since linking issues and pull requests directly to the card on the board is seamless.
            </li>
            <li>
                In addition to having accurate visualization of current work the Kanban board will allow us to maintain our focus on a specific number of tasks as we enforce WIP limits for cards in the in-progress column.
            </li>
        </ul>

        <h3>Pros and cons with other processes</h3>
        <p>
            Considering the requirements presented above we can conclude we have two primary methods to choose from - Scrum or Kanban. The following table summarizes pros and cons of choosing Kanban over Scrum:
        </p>
        <table>
            <tr>
                <th>Pros</th>
                <th>Cons</th>
            </tr>
            <tr>
                <td>
                    <ul>
                        <li>Kanban focuses on development over the business</li>
                        <li>Requirements are primarily created early while continuous. Because no “client” exists, there is no need to constantly revise requirements.</li>
                        <li>Our contributions would not be large enough to justify a full plan-driven model of Scrum.</li>
                        <li>Enforcing strategies that are strong foundations of Scrum is extremely difficult to manage as we might be working on different deliverables where tasks don’t transcend across several sprints.</li>
                        <li>Kanban makes it easier to distribute work evenly.</li>
                        <li>Kanban board columns can be adapted to fit our individual skill sets.</li>
                    </ul>
                </td>
                <td>
                    <ul>
                        <li>Kanban doesn’t support deadlines, will have to create our own on a person-to-person basis.</li>
                        <li>Kanban is very similar to scrum so we will have to be careful.</li>
                    </ul>
                </td>
            </tr>
        </table>

        <h4>Modifications to Kanban</h4>
        <p>
            Because of time constraints, it is not feasible to have Daily stand up meetings. As an alternative, we have a dedicated Discord channel where we report daily progress as each team member becomes available.
        </p>

    </div>
    <!-- deliverable 2 -->
    <hr class="style1">
    <div class="container-fluid wide deliverable" id="deliverable2" style="background-color: #CCDDCE; height: auto;">
        <h1 class="text-center">Deliverable 2</h1>

        <h2>Picked 6 Bugs or features</h2>
        <!-- issue 1 -->
        <div class="panel" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 1:</b> Type hint of DataFrame(...dtype...) excludes numpy scalar types such as np.int8</div>
            <div class="panel-body">
                <p><a href="https://github.com/pandas-dev/pandas/issues/31872">https://github.com/pandas-dev/pandas/issues/31872</a></p>
                <p>
                    DataFrame, a common object in pandas, throws a warning with a type check when using type np.int8 in its values. Currently, DataFrame can only hold the following types: str, np.dtype, and "ExtensionDtype". These are the python string primitive, a data
                    type object from numpy, and an extension data type object from pandas itself. When numpy integers are thrown in for a DataFrame (constructing a dataframe using pandas.DataFrame(data=d, dtype=np.int8), a type check error is thrown because
                    np.int8 is not part of nor an instance of str, np.dtype, and "ExtensionDtype".
                </p>
                <p>
                    To complete, we would likely go with the suggested solution of adding np.generic (a parent of np.int8) to the accepted types for the pandas DataFrame object. This would take nearly 2 hours to find the location of pandas DataFrame and its accepted types
                    and then adding np.generic, and it would take another hour to test and make sure it does not break anything in the process.
                </p>


            </div>
        </div>

        <!-- issue 2 -->
        <div class="panel" id="get-loc" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 2:</b> BUG: get_loc / get_indexer with NaT and tz-aware DatetimeIndex
            </div>
            <div class="panel-body">
                <p>
                    <a href="https://github.com/pandas-dev/pandas/issues/32572" target="_blank">https://github.com/pandas-dev/pandas/issues/32572</a>
                </p>
                <p>
                    One type that pandas uses for tracking datetimes better is NaT, which stands for Not a Time. This is similar to NaN, which is common in all languages as Not a Number, which represents missing or illegal number values. In the same fashion, NaT is put in
                    place for missing datetime values. For the bug, when get_loc (a function for converting a datetime to a local time) is called on a NaT value, the result is 0. Furthermore, when it is used to convert to a different time zone, then it
                    throws an error.
                </p>
                <p>
                    To complete, it would take about 6 hours to investigate both parts of this issue, determining why 0 is returned for local time and figuring out what the type issue is when converting to a different time zone. It would then take another 2 hours to fully
                    test our solution and make sure it does not break anything else in the code.

                </p>
                <p>
                    This was one of the issues we chose to tackle at first. After many hours of debugging, we figured out that the problem is in the logic, get_loc inside Index class is not properly handling some cases that are of “na” type: None, NaT,.. Adding the fix would
                    be easy, we simply checked for those cases using isna function.
                </p>
            </div>
        </div>

        <!-- issue 3 -->
        <div class="panel" id="issue3" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 3:</b> dataframe.groupby incorrect with multiindex and None value</div>
            <div class="panel-body">
                <p><a href="https://github.com/pandas-dev/pandas/issues/32492" target="_blank">https://github.com/pandas-dev/pandas/issues/32492</a></p>
                <p>
                    This bug concerns pandas’ groupby function. The group by function is defined as it would be in any other data management system; it takes input column names and then aggregates data across those columns. When you groupby on a DataFrame in pandas and do
                    not specify all the columns, then you will lose some data (as expected). However, when you try to call get_group on a list of items on the group by result that should not exist, it does not return a KeyError as expected.
                </p>
                <p>
                    To complete, it would take about 7 hours to investigate both the groupby and get_group function logic and determine the best way to fix it. It would also take another 2 hours to test our solution against our own requirements and the rest of the code.
                </p>
            </div>
        </div>

        <!-- issue 4 -->
        <div class="panel" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 4:</b> Rows order when using slice(None) on MultiIndex Dataframe.loc</div>
            <div class="panel-body">
                <p><a href=" https://github.com/pandas-dev/pandas/issues/31330" target="_blank">https://github.com/pandas-dev/pandas/issues/31330
					</a></p>
                <p>
                    This issue is based around a cosmetic bug when printing a DataFrame. When printing a DataFrame with several column hierarchies (ex. Cats: Black, Brown, …, Dogs: Black, Brown, …), pandas automatically sorts them using the order that they were inputted
                    when the DataFrame was created. This makes sense, but when the DataFrame is printed with a different hierarchy specified (Brown -> Black instead of Black -> Brown), the result DataFrame does not take the hierarchy specified into account,
                    and just prints what it would originally.
                </p>
                <p>
                    To complete, it would take about 5 hours to investigate the organization of DataFrame data and the print functions available to it and determine the best way to print the cosmetic result. It would take another 1 hour to check for edge cases of our fix
                    and test against the rest of the codebase.
                </p>


            </div>
        </div>

        <!-- issue 5 -->
        <div class="panel" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 5:</b>Inconsistency/bug when selecting from a data-frame using an unsorted DatetimeIndex</div>
            <div class="panel-body">
                <p><a href="https://github.com/pandas-dev/pandas/issues/30736" target="_blank">https://github.com/pandas-dev/pandas/issues/30736</a></p>
                <p>
                    This issue involves inconsistent indexing in pandas. In pandas, you can create an index of a range of values that you want, like between the min and max of your data or between two datetimes. The example on the issue page shows how sometimes, when creating
                    a DataFrame out of a disordered index, inconsistent and buggy results occur. Specifically, if you just want to add an hour value to the end of your range when you are selecting from your data, a KeyError occurs with an uninformative
                    message.
                </p>
                <p>
                    To complete, it would take about 6 hours to investigate the cause of the KeyError bug and determine a clean, scalable way to fix the way indexing works in this case. It would take another 2 hours to test our fix against our requirements and the rest of
                    pandas’ test suite
                </p>
            </div>
        </div>

        <!-- issue 6 -->
        <div class="panel" id="issue6" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Issue 6:</b> [BUG] Dataframe.rank() produces wrong results for float columns
            </div>
            <div class="panel-body">
                <p><a href="https://github.com/pandas-dev/pandas/issues/32593" target="_blank">https://github.com/pandas-dev/pandas/issues/32593</a></p>
                <p>
                    This bug concerns the Index’s rank() function for sorting columns in Dataframes. The specific issue is when infinite values are entered: For some reason, numpys np.inf is not always selected as the largest number in the ranking. This would raise problems
                    in mathematical analyses which one of pandas’ main uses, so this issue would be very beneficial to tackle.

                </p>
                <p>
                    To complete, it would take about 6 hours to investigate the reason why rank would mess up with some float columns and specifically np.int, and find a reasonable way to fix the ranking. It would take another 2 hours to test our fix against our requirements
                    and the rest of pandas’ test suite.
                </p>


            </div>
        </div>
        <br>
        <h3>Our Chosen Issues</h3>
        <section>
            <div class="panel" style="background-color: #CCDDCE; height: auto;">
                <div class="panel-heading"><b>Issue 3:</b> dataframe.groupby incorrect with multiindex and None value</div>
                <div class="panel-body">
                    <p><a href="https://github.com/pandas-dev/pandas/issues/32492" target="_blank">https://github.com/pandas-dev/pandas/issues/32492</a></p>
                    <p><a href="#issue3">Summary</a></p>
                    <p>
                        We chose this issue because it seemed of medium to significant difficulty, and would give us a greater understanding of the codebase (finding out about different types and how pandas deals with it, as well as looking at functions between objects as in
                        groupby). It also looks like an issue that would clear a lot of confusion for users of pandas, which is one of our team goals (increasing the usability of the project).


                    </p>
                    <p>
                        <b>Potential Risks:</b> While groupby does seem to have a specific use outside of pandas internal files, it may be used directly from certain functions inside pandas for efficiency. This could raise a problem if these other functions
                        are expecting to get results from group by in its current state, even if this current state is incorrect. To accommodate for this we will be running our solution against the entire test suite after our fix and make sure to go through
                        each potential failure to ensure we are not breaking anything else in our change
                    </p>


                </div>
            </div>

            <div class="panel" style="background-color: #CCDDCE; height: auto;">
                <div class="panel-heading"><b>Issue 6:</b> [BUG] Dataframe.rank() produces wrong results for float columns</div>
                <div class="panel-body">
                    <p><a href="https://github.com/pandas-dev/pandas/issues/32593" target="_blank">https://github.com/pandas-dev/pandas/issues/32593</a></p>
                    <p><a href="#issue6">Summary</a></p>
                    <p>
                        We chose this issue because it also seemed of medium to significant difficulty, and would give us a better understanding on the deeper logic of pandas. Like we mentioned in the summary, this could go deep into pandas’ code as it may have to do with dealing
                        with core comparison logic. It also seems like something that would fix a lot of other issues if done correctly, which would be a great use of our time.



                    </p>
                    <p>
                        <b>Potential Risks:</b> Thinking through this issue, this seems like this is likely a type ordering issue which fixing could have other ramifications. Specifically, depending on how the code is organized, there may be a function
                        that we need to change to accommodate for our specific example’s fix, and this function could be used for other ordering algorithms that depend on the function in different ways. We will again make sure to run our solution against
                        the entire test suite after our fix and make sure we are not breaking anything else in our change
                    </p>


                </div>
            </div>
        </section>

        <br>
        <h3>Software Process Proof</h3>
        <section>
            <p>
                As we stated in Deliverable 1, we used Kanban as our software process of choice when fixing the selected issues. This involved setting up the Kanban board, opening necessary communication channels, and making sure every task was completed by the due date.
                Here we will go over how we followed Kanban to complete this deliverable.

            </p>

            <h3>Kanban Board</h3>
            <p><a href="https://github.com/CSCD01-team14/pandas/projects/1" target="_blank">Link to the Board</a></p>
            <p>
                As planned, we used Github’s Projects board as our Kanban board. We first set up our board with the proper columns to track the lifetime of an issue: To do; In progress, Implemented; Review in Progress, Reviewer approved, waiting for merge; Merging; Done.

            </p>
            <p>
                We then split up our assignment into tasks that would be put together to complete the work needed for the deliverable (ex. Choosing five issues to develop, and Shortlisting it to 2 issues). For each task, as per Kanban guidelines, we made sure to write
                a small description of the task, how long it would take, link the necessary resources, and its deadline. Given that we filled out each task with a corresponding description, and knew the estimated time, we were sure that each of the tasks
                would be completed (and therefore the deliverable) by the due date.
            </p>
            <p>
                <img src="images/deliverable2/kanban.png" alt="kanban Board image">

            </p>

            <h3><u>Daily Asynchronous Standup Meetings</u></h3>
            <p>Another part of the software process that we agreed on is doing virtual standup meetings to update the other group members on progress. We did this in a dedicated channel in our method of communication Discord called “daily-standups”. Every
                day near the end of the project, we would send messages like the one shown below to update other team members on what we are currently doing for the project.</p>
            <p>
                <img src="images/deliverable2/meeting.png" alt="" srcset="">
            </p>
            <p>
                As you can see, each message would consist of a “Do” part for what was done that day, “Todo” for what they have left to do in the future, and “Blocked” for what they need to do but cannot because of some dependency they are waiting on (another team member’s
                task, external dependency like a pull request, etc.) This worked great for us because we were able to stay updated with each other while not compromising our busy schedules as students. Furthermore, it allowed for follow up questions and
                conversation, which is not as easily applicable through just the Kanban board.
            </p>
            <h3><u>Why Kanban Came in Handy</u></h3>
            <p>
                Using Kanban helped us in the project because we were allowed flexibility in our development. For any task in the Kanban board, we were allowed to update it or add new tasks as our understanding of the issues increased over the course of the deliverable.
                Since Kanban emphasizes continuous updates, we had that flexibility to reroute at any time to ensure the deliverable was completed. For example, when we wanted to investigate other issues to try and implement, we were able to record what
                we were currently working on and place it in the “To do” column, as well as add new tasks relevant to the new issue and place it in the “In progress” column.

            </p>
            <p>
                It was also extremely helpful since we were able to accomodate for our busy schedules as students by having a visual guide to completing the work for the deliverable. Every day we could check at any time what tasks needed to be done and how long it would
                take for them so each team member could fit it into their schedule correctly (among their other assignments). This way we were able to complete all tasks asynchronously, while also staying active on the Discord for synchronous communication.

            </p>
        </section>

        <br>
        <h3>Technical Commentary</h3>
        <section>
            <!-- issue 3 -->
            <div class="panel" style="background-color: #CCDDCE; height: auto;">
                <div class="panel-heading"><b>Issue 3:</b> dataframe.groupby incorrect with multiindex and None value</div>
                <div class="panel-body">
                    <p><a href="https://github.com/pandas-dev/pandas/issues/32492" target="_blank">https://github.com/pandas-dev/pandas/issues/32492</a></p>
                    <p>
                        <b>How these changes affect the design</b>

                    </p>

                    <p>
                        The bugfix implemented for the get_group function does not affect the overall structure of the project. This bugfix is adding a verifier to the output of a helper function (_get_index) within get_group. The helper function sometimes gives an unexpected
                        output but is used in many more functions than get_group so we decided to add a verifier within get_group to preserve as much of the codebases’ integrity as possible. Thus, “pandas/core/groupby/groupby.py” was the only file that
                        was changed as it is the file with get_group.



                    </p>
                    <p>
                        The only issue that arises is that many other functions call upon the get_group function. When running the extensive pytest pandas test suite, we will see a few (12) test cases fail now as they are given a different error. Previously, they were using
                        invalid input and expected a different error to appear through the use of a different function. These test cases will have to be revised and updated, but that is beyond the scope of this bugfix.

                    </p>
                    <p><a href="https://github.com/CSCD01-team14/pandas/pull/2" target="_blank">Pull Request</a></p>
                    <p><a href="https://github.com/CSCD01-team14/pandas/pull/2/files#diff-c53c0d90d98374520ad40b3808903fd1" target="_blank">Test suite</a></p>
                </div>
            </div>
            <!-- issue 6 -->
            <div class="panel" style="background-color: #CCDDCE; height: auto;">
                <div class="panel-heading"><b>Issue 6:</b> [BUG] Dataframe.rank() produces wrong results for float columns</div>
                <div class="panel-body">
                    <p><a href="https://github.com/pandas-dev/pandas/issues/32593" target="_blank">https://github.com/pandas-dev/pandas/issues/32593</a></p>
                    <b>How these changes affect the design</b>
                    <p>
                        The bugfix does not affect the structure of the project. It just slightly changes the behavior of rank of DataFrame when DataFrame consists of floats. The only thing that changed is rank_2d function inside algos.pyx file in pandas/_libs folder.

                    </p>
                    <p>
                        <b>More details about the bug and rank_2d function:</b>

                    </p>
                    <p>
                        Rank function is supposed to assign ranks for numbers inside the DataFrame (either ascending or descending). Suppose we have a data frame of 1 column: [9, 2, 3]. Since 2 is lowest, it gets rank 1; 3 gets rank 2; and 9 gets rank 3. We’re using all valid
                        numbers here, but the column can also contain np.nan (not a number), np.inf (infinity), -np.inf (minus infinity). When the data type of the dataframe is int, they should all be the same because infinity is not a valid number for
                        int.
                    </p>
                    <p>
                        However, inf and -inf are valid numbers for float, in particular, inf would be the largest number, and - inf is the lowest. So you would expect df.rank() to rank them like that, however that is not the case. If you are ranking ascending, then inf is treated
                        as nan, and if you are ranking descending, -inf is treated as nan (because for type(int) it is the same). In particular, they assigned nan_value = np.inf (for ascending case) and nan_value = -np.inf for float case. We changed this
                        to nan_value = np.NaN instead.

                    </p>

                    <p><a href="https://github.com/CSCD01-team14/pandas/pull/3/" target="_blank">Pull Request</a></p>
                    <p><a href="https://github.com/CSCD01-team14/pandas/pull/3/files#diff-ef1ed2b4659b2621060565a4db36ef3c" target="_blank">Test suite</a></p>

                </div>
            </div>
        </section>

    </div>

    <!-- deliverable 3 -->
    <hr class="style1">
    <div class="container-fluid wide deliverable" id="deliverable3" style="background-color: #CCDDCE; height: auto;">
        <h1 class="text-center">Deliverable 3</h1>

        <h2>Descriptions of Two selected issues/features</h2>

        <!-- issue 1 -->
        <div class="panel" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b> BUG: </b> get_loc / get_indexer with NaT and tz-aware DatetimeIndex
            </div>
            <div class="panel-body">
                <p>
                    <a href="https://github.com/pandas-dev/pandas/issues/32572" target="_blank">https://github.com/pandas-dev/pandas/issues/32572</a>
                </p>
                <p>
                    Upon dropping this issue in <a href="#get-loc">previous deliverable</a> due the complexity and unexplored territory of handling operations on DateTimeIndex. The fix to this issue seemed as simple as adding additional login to get_indexer,
                    where we can handle the case for NaT such that instead of searching for the “nearest” location of NaT, the get_loc function would return NaT since, it undefined behaviour to look for a time closest to “Not A Time”.

                </p>
                <p>
                    However, there is more to this since an additional issue is that when the data range is tz aware, a TypeError exception occurs. This is because the get_loc function returns the location of a target by recursively calling get_indexer on the left and right
                    of the DateTimeIndex and keeps subtracting the target from the Objects in the DateTimeIndex. Although this behavior returns a “0” for tz unaware dates , which by itself is inaccurate, the same behaviour is not replicated for tz aware
                    dates due to an unhandled case.

                </p>

                <p>
                    Consider searching for NaT in a tz aware date range. In this scenario, a dtype mismatch occurs between the objects in the DatetimeIndex and the target of the search. This is mainly because the NaT Datetime is not tz aware by default. Because of this reason
                    both the Indexes (the date range and the target) are casted as dtype Objects inside the get_indexer function. This will not work for the indexer since the indexer is subtracting the target from the objects in the Date range. During
                    the subtraction the Datetime Target Object is converted into DatetimeArray which cannot be subtracted from ndArray which holds the Date range

                </p>

                <p>
                    <b>Code Change:</b> Inside the _maybe_promote method, casting NaT Datetime that is tz unaware into a tz aware Datetime will prevent the eventual mismatch and will not throw a type error. Get_loc for tz aware date range at this point
                    will behave similarly as tz unaware dates. <a href="https://github.com/CSCD01-team14/pandas/blob/3059a2bfdebfc8fe1d8502039668dfacdf2cefb5/pandas/core/indexes/datetimes.py#L529">_maybe_promote</a> function inside the datetimes.py is
                    a potential location where this change could be applied, the tz of dates in date range can be used to promote the tz unware NaT when ever the target date does not have a tz.
                </p>

                </p>

            </div>
        </div>

        <!-- issue 2 -->
        <div class="panel" id="issue3" style="background-color: #CCDDCE; height: auto;">
            <div class="panel-heading"><b>Feature Request: </b> "Skiprows" by a condition or set of conditions #32072</div>
            <div class="panel-body">
                <p><a href="https://github.com/pandas-dev/pandas/issues/32072" target="_blank">https://github.com/pandas-dev/pandas/issues/32072</a></p>
                <p>
                    Currently the functionality of reading a CSV file allows users to skip certain rows by indicating which row numbers they want to eliminate. Building upon this functionality, we would filter by the contents of each row. This would involve passing in a
                    boolean function that would indicate the conditions for each column and any row that does not pass is eliminated from the import. This is similar to how skiprows currently takes in a callable (can be a lambda function) that returns
                    a boolean and runs the row number on the callable to determine if the row should be kept or not. This would help improve usability and make trimming down input significantly easier than the current columns and workarounds.

                </p>


            </div>
        </div>

        <br>
        <h2>The Chosen One</h2>
        <section>
            <h3>
                <u><b>Feature Request: </b> "Skiprows" by a condition or set of conditions #32072</u>
            </h3>

            <div>
                <p><b>Reason to Choose</b></p>
                <p>
                    Our goal for this project was to help researchers process their data. Imagine our surprise when the function used to read from comma-separated values files (csv files) was incomplete. A pandas user requested the ability to have the skiprows parameter
                    of the read_csv function to accept conditions as one of its parameters. Veteran contributors gfyoung and jreback, even assumed this functionality to already exist and were taken aback that it did not exist. As one of the most basic
                    yet most important file formats, an improvement to this will greatly contribute to the greater scientific community as many users use the read_csv function. Adding new features that users would assume to be there will be of great help
                    to all future users, meeting our project goal.
                </p>
                <p><b>Implementation Ideation Details</b></p>
                <p>
                    Adding to the current functoinality of skiprows, we would take in a string, which using the table schema provided in dtype, would be run using query from pandas Datatype, allowing the rows that do not pass the boolean outlined to be removed from the resulting table.
                </p>
                <p><b>Choosing this feature over get_loc bug</b></p>
                <p>
                    get_loc, despite being an interesting issue, fails to be significani enough to put in the time and effort which we can use to add above mentioned functionality. The bug caused due to invalid NaT being passed in to get_indexer, can be fixed fairly easily
                    by ensuring to cast NaT to tx aware Datetime Object. However, this doesn't fix the entire issue. The conversation on the issue page suggests, the result 0, for absent NaT in the date range is not valid and get_loc must return NaT.
                    Although this could be worked upon, consequences of not fixing this functionality is not as effective as compared to the outcome skiprows feature. This is one of the reasons to chose skiprows over get_loc.
                </p>
                <p>
                    <b>Acceptance Tests: </b> <a href="https://github.com/pandas-dev/pandas/commit/87266f44a18494d6d2ffba363603186399dd3cae" target="_blank">Link to github</a>
                </p>


            </div>

            <h2>Architecture Document</h2>
            <div id="overall-structure">
                <h3><u>Overall Structure</u></h3>
                <img src="./images/deliverable3/overall.png" alt="updated view of the architecture">
                <p>
                    If you compare it to our previous view, you can see that our entire view from before has been put in the “Core” component here, with less detail from before for clarity. We still have the PandasObject, Operation, and ExtensionDTypes as they are important
                    to understanding the core component of the architecture. More detailed views of these core components can be found in our first overview of the architecture at <a href="https://d01-team14.netlify.com/#deliverable1">Deliverable 1</a>.
                    As for the new components Plotting, IO, and Error, we included them as we found them to be important parts of the architecture when working on our issues in Deliverable 2. More detailed views and descriptions will follow, but these
                    basically flesh out how the core functionality of pandas is viewed, used, and debugged.
                </p>
            </div>
            <div id="tests">
                <h3><u>Tests</u></h3>
                <img src="./images/deliverable3/tests.png" alt="">
                <hr class="style1">
                <p>
                    The first new component of pandas we learned about are the Tests. These have no direct relationship with how the code of pandas works, but for Deliverable 2 it was important to learn about it for making sure our changes are compatible with the rest of
                    the codebase.

                </p>
                <p>
                    For the structure of the tests, pandas has a pretty open test suite, which is likely a design decision for increasing the accessibility of open source contributions. By “open” I mean that there are clear categories for parts of the codebase (like testing
                    how it uses Numpy in BaseNumPyTests, DecimalArrays in BaseDecimal, and SparseArrays in BaseSparseTests). Tests are placed in categories for organization, but also for holding functions that would be helpful for doing the tests in that
                    category (ex. assert_series_equal(left, right) in BaseDecimal).

                </p>
                <p>There are also test suites that are not part of any category, and so they can just be placed anywhere in the tests folder, with an appropriate name and folder structure. An example of this is with TestTimedeltaMultiplicationDivision at
                    tests/scalar/timedelta/test_arithmetic.py, a test suite that just inherits “object” and tests TimeDelta with multiplication, division, and floor operations.

                </p>

            </div>
            <div id="errors">
                <h3><u>Errors</u></h3>
                <img src="./images/deliverable3/errors.png" alt="">
                <p>
                    We next learned more about Errors in pandas, which uses inheritance from Python’s Exception class to create similar errors and warnings specifically for pandas’ use. This design is used not only for neatly integrating pandas’ errors with Python’s standard
                    ones, but also for more readable errors and warnings when pandas is being used incorrectly.
                </p>

                <p>
                    An example error in pandas is an UnsortedIndexError. As you can see in the diagram, it is a child of KeyError. KeyError is Python’s own error for accessing data that does not exist using a key, like with dictionaries. UnsortedIndexError is thrown when
                    you try to slice an index that has not been sorted yet, since pandas requires a sort before working with indices like that. Since this involves trying to access data that has not been formatted yet to be accessed by keys at all, pandas
                    deems this a type of KeyError and constructs the design as such.
                </p>
                <p>
                    Pandas also has Warnings, which is also a child of Exception and is just there to warn the user about there existing a more optimal way of using pandas. Some example warnings are for Performance, Parsing, and Dtypes.
                </p>

            </div>
            <div id="io">
                <h3><u>IO</u></h3>
                <img src="./images/deliverable3/IO.png" alt="">
                <p>
                    Pandas also has an I/O component, which you could probably already assume is how it takes user input and outputs to the screen and file system. The three main parts of this IO component are the Parser, the Formatter, and the Writer.
                </p>
                <p>
                    The Parser is used for taking input from files and directly creating a pandas structure from it. For example, pandas allows the user to input a json file in a specific format and create a Series or a DataFrame out of its data, which is good for holding
                    large data on your system and importing it. Note that this is an example of the Factory design pattern: instead of directly calling a constructor, data types can be created by calling the Parser function. Note that the Parser uses
                    NumPy because it calls their Parsers in certain scenarios.

                </p>
                <p>
                    The Formatter is used for organizing all the string formats for pandas’ data types for easy output. This is useful for quickly viewing data, and it is incredibly important for pandas to have this because pandas has a lot of unique data types. The Writer
                    is essentially the opposite of the Parser, it allows pandas to take data held in memory and write it to a file in the system, which can be read by the Parser at a later point.

                </p>

            </div>
            <div id="plotting">
                <h3><u>Plotting</u></h3>
                <img src="./images/deliverable3/plotting.png" alt="">
                <p>
                    One more component we investigated in pandas was how pandas does Plotting. Here we see that pandas relies heavily on Matplotlib’s plotting functionality to display data. This design decision was made likely for the same reason pandas uses NumPy’s functionality
                    in other places; reuse-oriented design in these parts allow for pandas to focus on other areas that make it unique, like their unique data structures and functions.

                </p>
                <p>
                    As you can see, the Plotting part of pandas is pretty self-explanatory. There is a main MatplotlibPlot class that uses Matplotlib’s functionality to create a plot, and then specific plots under that to specify the types of plots made (bar, scatter, pie,
                    histogram, etc.) Note that pandas still needs to make its own classes for each plot because it needs to isolate the functionality needed to translate pandas’ own data types to Matplotlib’s plotting interface.

                </p>
            </div>
        </section>

    </div>

    <hr class="style1">
    <div class="container-fluid wide deliverable" id="deliverable4" style="background-color: #CCDDCE; height: auto;">
      <h1 class="text-center">Deliverable 4</h1>

      <h2>User Guide</h2>
      <p>
        <strong>skiprows : callable, optional (Option for read_csv())</strong>
      </p>
      <p>
        Lines to skip based on the callable function. The callable function will be evaluated against the row values, returning True if a row should be skipped and False otherwise. 
        An example of a valid callable argument would be: <em>“col_1 > 2 and col_3 == 4”</em>
      </p>
      <p>To use, first create a callable as a string:
        <div class="tabbed"><em>mask = "(area &gt; 8.516 or area &lt; 3.286)"</em></div></p>
      <p>
        Then add in the skiprows parameter to your read_csv function.
        <div class="tabbed"><em>df = pd.read_csv('brics.csv', skiprows=mask, dtype=schema)</em></div>
      </p>

      <h2>Design Document</h2>
      
      <h3>Overview of Feature</h3>
      <p>
        Before our implementation, pandas was missing the functionality to skip rows based on a string query. This way users can filter rows based on its contents, instead of just the row numbers which is all that the current skiprows supports.
      </p>
      <p>
        This would involve passing in a boolean query that would indicate the conditions for each column (like “population > 1200”) and any row that does not pass is eliminated from the import. 
        This would help improve usability and make trimming down input significantly easier than current workarounds.
      </p>

      <h3>Investigating the Relevant Code</h3>
      <p>
        For our implementation, we made sure to investigate where would be the best place to put in our changes. Reading a csv in pandas involves several levels going all the way down to the io layer, which is written in c (more specifically, Cython) to increase efficiency.
      </p>
      <p>
        Here is a high level trace of the essential and relevant pieces of code when reading a csv:
      </p>
      <img src="images/deliverable4/overview.png" alt="">
      <p>
        <br/>
        <u>read_csv</u>: <a href="https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L683">https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L683</a><br/>
        This would help improve usability and make trimming down input significantly easier than current workarounds.
      </p>
      <p>
        <u>TextFileReader</u>: <a href="https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L449">https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L449</a><br/>
        This is the python object used for managing all the data read in a text file. In this case it is a csv file, but the data is treated the same: holding the rows, columns, and metadata about the file. The TextFileReader has several useful functions like read() that we will be following to see how it interacts with the actual files.
      </p>
      <p>
        <u>TextFileReader.read()</u>: <a href="https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L1128">https://github.com/pandas-dev/pandas/blob/master/pandas/io/parsers.py#L1128</a><br/>
        This is where the TextFileReader interacts with Cython and the c file. Specifically, it calls it’s engine (c or Python)’s parser to get the data from the specified file and then organizes it into columns and rows in the TextFileReader’s attributes. This is then passed back up to read_csv as readable data in a Dataframe format.  
      </p>
      <p>
        <u>Tokenize_bytes()</u>: <a href="https://github.com/pandas-dev/pandas/blob/master/pandas/_libs/src/parser/tokenizer.c#L711">https://github.com/pandas-dev/pandas/blob/master/pandas/_libs/src/parser/tokenizer.c#L711</a><br/>
        This is where the c file reads the data from the file. It is called tokenizer because it treats each character and string in the file as a token, and depending on what the token is it modifies the data sent eventually sent back up to TextFileReader. It uses a switch case to go token by token in a line by line format, checking whether the current token is a character to add on to the previous token, a delimiter, a new line, and so on. Note that at any point in the tokenizer file, the strings are only treated as strings or characters.   
      </p>
      <p>
        Skiprows comes into play here by keeping a counter of what row the tokenizer is at. If the current row is one to be skipped as specified by the list of rows, the number of rows from the start, or the lambda function, then the tokenizer just goes to the next new line and therefore ignores the specified row.
      </p>

      <h3>Details for Implementation</h3>
      <p>
        For our implementation, we decided to make use of pandas query() function to ensure better integration with the code. The pandas query function takes in a dataframe and a boolean expression and filters the dataframe based on whether the specified column values pass or fail the boolean expression. An example of this would be to filter out certain cities in Ontario based on population, assuming there is a “population” column you can pass in the full dataframe with the data and then query “(population > 1200)”. 
      </p>
      <p>
        By using query when the Dataframe is created we can ensure that our code is depending on query functionality already existing in pandas. This allows for easier integration in the code, with the added benefit of not needing to specifically change how the filter works in read_csv if new changes in query are made. This allows for a way for the users to easily filter out data from their csvs when importing it into pandas.
      </p>
      <p>
        The reason we did not edit the actual tokenizer.c file to filter the rows is due to the current implementation. As we mentioned before, the tokenizer file that reads in the data for the csvs is done reading the file as one would normally do it: reading left to right, line by line. Skipping specific rows by row numbers in this format is easy because one would just need to keep a counter for what the current row is, and skip to the next line if the current one needs to be skipped. This is why the current skiprows functionality only focuses on specific row numbers.
      </p>
      <p>
        However, skipping rows based on specific column values with this format is not feasible. For example, say you wanted to skip a row based on whether its fifth column value. To do this with the current implementation of reading csvs, we would have to read the first five column values anyways, to know where the fifth value is located. We would also have to implement a way to translate the tokens into pandas comparable format, since they are all treated as strings in the tokenizer. This is why we went with implementing the query functionality when the Dataframe is actually created.
      </p>
      <p>
        With the code changes specified in this commit <a href="https://github.com/CSCD01-team14/pandas/commit/4c2dd8f418b17cb75aa6f2359756892263da7c16">link</a>, we have our new sequence diagram:
      </p>
      <img src="images/deliverable4/overview2.png" alt="">

      <h2>Acceptance Tests</h2>
      <h3>Acceptance Test #1:</h3>
      <p>
        The ‘customer’ (issue creator) provided this example file<br/>
        <em># data file path: foo/bar/data.csv</em>
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>col_1</th>
          <th>col_2</th>
          <th>...</th>
          <th>col_n</th>
        </tr>
        <tr>
          <td>0</td>
          <td>940</td>
          <td>15</td>
          <td>...</td>
          <td>0.023</td>
        </tr>
        <tr>
          <td>1</td>
          <td>1040</td>
          <td>52</td>
          <td>...</td>
          <td>0.430</td>
        </tr>
        <tr>
          <td>2</td>
          <td>1530</td>
          <td>52</td>
          <td>...</td>
          <td>0.302</td>
        </tr>
        <tr>
          <td>3</td>
          <td>753</td>
          <td>43</td>
          <td>...</td>
          <td>0.450</td>
        </tr>
        <tr>
          <td>4</td>
          <td>890</td>
          <td>32</td>
          <td>...</td>
          <td>0.023</td>
        </tr>
      </table>
      <p>
        They can establish the following schema for the types:<br/>
        <em>
          schema={"col_1": int, ..., "col_n": float}
        </em>
      </p>
      <p>
        Then create a boolean query function in a string which we will call ‘mask’:
        <br/><em>mask = "col_1 &geq; 1000</em>
      </p>
      <p>
        Now when they read from the file (with read_csv) and include the skiprows parameter:
        <br/><em>df = pd.read_csv('foo/bar/data.csv', skiprows=mask, dtype=schema)</em>
      </p>
      <p>
        They will be able to skip over rows based on this boolean condition and should expect a result like:
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>col_1</th>
          <th>col_2</th>
          <th>...</th>
          <th>col_n</th>
        </tr>
        <tr>
          <td>1</td>
          <td>1040</td>
          <td>52</td>
          <td>...</td>
          <td>0.430</td>
        </tr>
        <tr>
          <td>2</td>
          <td>1530</td>
          <td>52</td>
          <td>...</td>
          <td>0.302</td>
        </tr>
      </table>

      <h3>Acceptance Test #2:</h3>
      <p>
        The ‘customer’ would have an expected input similar to this file:<br/>
        <em>#brics.csv</em>
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>country</th>
          <th>capital</th>
          <th>area</th>
          <th>population</th>
        </tr>
        <tr>
          <td>0</td>
          <td>Brazil</td>
          <td>Brasilia</td>
          <td>8.516</td>
          <td>200.4</td>
        </tr>
        <tr>
          <td>1</td>
          <td>Russia</td>
          <td>Moscow</td>
          <td>17.10</td>
          <td>143.5</td>
        </tr>
        <tr>
          <td>2</td>
          <td>India</td>
          <td>New Delhi</td>
          <td>3.286</td>
          <td>1252</td>
        </tr>
        <tr>
          <td>3</td>
          <td>China</td>
          <td>Beijing</td>
          <td>9.597</td>
          <td>1357</td>
        </tr>
        <tr>
          <td>4</td>
          <td>South Africa</td>
          <td>Pretoria</td>
          <td>1.221</td>
          <td>52.98</td>
        </tr>
      </table>
      <p>
        They can establish the following schema for the types:<br/>
        <em>
          schema={"country": String, "capital": String, "area": int, "population": int}
        </em>     
      </p>
      <p>
        Then create a boolean query function in a string which we will call ‘mask’:
        <br/><em>mask = "area &lt; 8.516"</em>
      </p>
      <p>
        Now when they read from the file (with read_csv) and include the skiprows parameter:
        <br/><em>df = pd.read_csv('brics.csv', skiprows=mask, dtype=schema)</em>
      </p>
      <p>
        They will be able to skip over rows based on this boolean condition and should expect a result like:
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>country</th>
          <th>capital</th>
          <th>area</th>
          <th>population</th>
        </tr>
        <tr>
          <td>2</td>
          <td>India</td>
          <td>New Delhi</td>
          <td>3.286</td>
          <td>1252</td>
        </tr>
        <tr>
          <td>4</td>
          <td>South Africa</td>
          <td>Pretoria</td>
          <td>1.221</td>
          <td>52.98</td>
        </tr>
      </table>

      <h3>Acceptance Test #3:</h3>
      <p>
        The ‘customer’ would have an expected input similar to this file:<br/>
        <em>#brics.csv</em>
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>country</th>
          <th>capital</th>
          <th>area</th>
          <th>population</th>
        </tr>
        <tr>
          <td>0</td>
          <td>Brazil</td>
          <td>Brasilia</td>
          <td>8.516</td>
          <td>200.4</td>
        </tr>
        <tr>
          <td>1</td>
          <td>Russia</td>
          <td>Moscow</td>
          <td>17.10</td>
          <td>143.5</td>
        </tr>
        <tr>
          <td>2</td>
          <td>India</td>
          <td>New Delhi</td>
          <td>3.286</td>
          <td>1252</td>
        </tr>
        <tr>
          <td>3</td>
          <td>China</td>
          <td>Beijing</td>
          <td>9.597</td>
          <td>1357</td>
        </tr>
        <tr>
          <td>4</td>
          <td>South Africa</td>
          <td>Pretoria</td>
          <td>1.221</td>
          <td>52.98</td>
        </tr>
      </table>
      <p>
        They can establish the following schema for the types:<br/>
        <em>
          schema={"country": String, "capital": String, "area": int, "population": int}
        </em>     
      </p>
      <p>
        Then create a boolean query function in a string which we will call ‘mask’. Note that this is a bi-conditional and is in fact, an example of working multi-conditional queries:
        <br/><em>mask = "(area &leq; 8.516 and population &gt; 1200)"</em>
      </p>
      <p>
        Now when they read from the file (with read_csv) and include the skiprows parameter:
        <br/><em>df = pd.read_csv('brics.csv', skiprows=mask, dtype=schema)</em>
      </p>
      <p>
        They will be able to skip over rows based on this boolean condition and should expect a result like:
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>country</th>
          <th>capital</th>
          <th>area</th>
          <th>population</th>
        </tr>
        <tr>
          <td>3</td>
          <td>China</td>
          <td>Beijing</td>
          <td>9.597</td>
          <td>1357</td>
        </tr>
      </table>

      <h3>Acceptance Test #4:</h3>
      <p>
        The ‘customer’ would have an expected input similar to this file:<br/>
        <em>#sales.csv</em>
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>item</th>
          <th>employee</th>
          <th>cost</th>
          <th>quantity</th>
        </tr>
        <tr>
          <td>0</td>
          <td>Coke</td>
          <td>Bob</td>
          <td>2.99</td>
          <td>1</td>
        </tr>
        <tr>
          <td>1</td>
          <td>Chips</td>
          <td>Bob</td>
          <td>1.59</td>
          <td>1</td>
        </tr>
        <tr>
          <td>2</td>
          <td>Milk</td>
          <td>Alice</td>
          <td>6.49</td>
          <td>1</td>
        </tr>
        <tr>
          <td>3</td>
          <td>KitKat</td>
          <td>Alice</td>
          <td>1.99</td>
          <td>2</td>
        </tr>
        <tr>
          <td>4</td>
          <td>Coke</td>
          <td>Mallory></td>
          <td>2.99</td>
          <td>1</td>
        </tr>
      </table>
      <p>
        They can establish the following schema for the types:<br/>
        <em>
          schema={"item": str,
          "employee": str,
          "cost": float,
          "quantity": int}
        </em>     
      </p>
      <p>
        Then create a boolean query function in a string which we will call ‘mask’:
        <br/><em>mask = "employee == ‘Alice’"</em>
      </p>
      <p>
        Now when they read from the file (with read_csv) and include the skiprows parameter:
        <br/><em>df = pd.read_csv(sales.csv', skiprows=mask, dtype=schema)</em>
      </p>
      <p>
        They will be able to skip over rows based on this boolean condition and should expect a result like:
      </p>
      <table class="dataframe-table">
        <tr>
          <th/>
          <th>item</th>
          <th>employee</th>
          <th>cost</th>
          <th>quantity</th>
        </tr>
        <tr>
          <td>2</td>
          <td>Milk</td>
          <td>Alice</td>
          <td>6.49</td>
          <td>1</td>
        </tr>
        <tr>
          <td>3</td>
          <td>KitKat</td>
          <td>Alice</td>
          <td>1.99</td>
          <td>2</td>
        </tr>
      </table>

      <h2>Evidence of good software development process</h2>
      <p>
        <a href="https://trello.com/invite/b/8KyMbjlR/ff45084ba20293d4ef1b9ade92b5177c/cscd01">https://trello.com/invite/b/8KyMbjlR/ff45084ba20293d4ef1b9ade92b5177c/cscd01</a>
      </p>
      <p>
        By drawing from our experience using Kanban in previous deliverables and building upon the process we adopted in D3 we realized the need to add a few rules from XP to enable us to focus on getting things done more collaboratively and efficiently:
      </p>
      <ul>
        <li>
          Investigating the feature to be added required a coherent approach with efficient use of time for tracing the code. It would be unproductive for all developers to trace the code for a few days and potentially misunderstanding the implementation of the existing architecture. We carried out “pair programming” (in this case investigating and tracing the code in pairs) virtually as effectively as possible before the implementation, by having smaller groups of team members work closely towards a specific part of investigation e.g. tracing the C engine for skiprows vs usage of df.query in pandas
        </li>
        <li>
          Lack of synchronous meetings caused some gaps in communications that would eventually make subsequent communication in meetings, time-consuming. To tackle this, in addition to asynchronous updates in #standups, we decided to have virtual standups every day via discord audio channel. Here, we re-group and discuss tasks that are blocking us from moving forward. This also includes bridging the gap between the aforementioned subgroups, so we can ensure that we are on the same page and continue to move towards the same direction. Meetings were rapidly scheduled using when2meets after finishing a standup.
        </li>
        <li>
          We moved from Github Boards to Trello since more flexibility was required in defining and assigning each task. Using Trello also helped outline a more structured approach to our existing process
            <ul>
                <li>
                  We used due dates for each task. This helps us give our daily standups a starting point i.e What’s due and what’s delayed.
                </li>
                <li>
                  We used the process power-Up in Trello to encapsulate blocked status of tasks or issues to help us resolve it more effectively.
                  <img src="images/deliverable4/trello.png" alt="">
                </li>
                <li>
                  The power-up attaches a “Process” to a Card with a list, that refers to related to the trello cards, each having the states “Open”, “Started” or “Done”. A state of “On Hold” is automatically assigned to a subtask if previous tasks before a holding point, are not “Done”
                  <br/><img src="images/deliverable4/trellocards.png" style="width: 40%" alt="">
                </li>
                <li>
                  This allows the Kanban board to do the most of the communication during the daily standups and especially during the day when we are not in contact and work on individual tasks    
                </li>
            </ul>
        </li>
      </ul>

      <h3>Benefits of adding aspects of XP while using Kanban</h3>
      <p>
        Task distribution became fairly natural since during the initial stage of Understanding the specific aspect of the architecture for implementing the feature was done collaboratively and in pairs. This helped each of the team members to selectively choose the tasks that they were suitable for by drawing upon their interactions with the fellow team member they worked with
      </p>
      <p>
        A Stricter priority of work, combined with daily standups where we reflect on the holding points of our process on the Kanban board helped us maintain the consistency of the process resulting in meeting daily and weekly deadlines more successfully as we approached the submission date.
      </p>
      <img src="images/deliverable4/kanban.PNG" alt="">


    </div>


    <script src="./js/main.js"></script>
</body>

</html>
